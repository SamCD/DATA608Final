{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = 'This project is meant to address dual issues that have been in the news, especially local news, \\\n",
    "often as of late. On the one hand is the issue if school choice and zoning, and on the other hand the issue of \\\n",
    "standardized testing for elite high schools (i.e. SHSAT). \\\n",
    "\\\n",
    "Using open data from NYC.gov, this project attempts to gain more insight into the specialized admissions process \\\n",
    "through data aggregation and visualization. Notably, it is meant to give support to the possibility of expanding the \\\n",
    "specialized high school system within NYC by highlighting the different types of possible specializations as well as \\\n",
    "identify underserved areas of the city that would benefit from an expansion of this system. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import plotly.express as px\n",
    "import geopy.distance\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set, many fields are broken up into smaller sections, I am guessing for efficiency on the provider's end, however I am going to aggregate the similar columns for data anlysis purposes\n",
    "\n",
    "Here I also identify base fields that can be used, such as dbn, which is used as a primary key, and latitude and longitude for mapping purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseCols = [\n",
    "'dbn'\n",
    ",'school_name'\n",
    ",'borocode'\n",
    ",'overview_paragraph'\n",
    ",'borough'\n",
    ",'latitude'\n",
    ",'longitude'\n",
    ",'bin'\n",
    ",'bbl'\n",
    ",'nta'\n",
    ",'total_students'\n",
    ",'neighborhood'\n",
    "]\n",
    "\n",
    "specialCols = [\n",
    "'academicopportunities1'\n",
    ",'academicopportunities2'\n",
    ",'academicopportunities3'\n",
    ",'academicopportunities4'\n",
    ",'academicopportunities5'\n",
    ",'academicopportunities6'\n",
    ",'advancedplacement_courses'\n",
    ",'psal_sports_boys'\n",
    ",'psal_sports_girls'\n",
    ",'psal_sports_coed'\n",
    ",'school_sports'\n",
    ",'interest1'\n",
    ",'interest2'\n",
    ",'interest3'\n",
    ",'interest4'\n",
    ",'interest5'\n",
    ",'interest6'\n",
    ",'interest7'\n",
    ",'interest8'\n",
    ",'interest9'\n",
    ",'interest10'\n",
    ",'common_audition1'\n",
    ",'common_audition2'\n",
    ",'common_audition3'\n",
    ",'common_audition4'\n",
    ",'common_audition5'\n",
    ",'common_audition6'\n",
    ",'common_audition7'\n",
    ",'common_audition8'\n",
    ",'common_audition9'\n",
    ",'common_audition10'\n",
    ",'specialized'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://data.cityofnewyork.us/resource/23z9-6uk9.csv')\n",
    "\n",
    "baseDF = df[baseCols] #id, name and location of high schools\n",
    "\n",
    "MSDirDF = pd.read_csv('https://data.cityofnewyork.us/resource/uqxv-h2se.csv')\n",
    "MSDirDF = MSDirDF[['schooldbn','latitude','longitude']] #id and location of middle schools (additional info in feeder data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I am coalescing similar columns into one for efficiency and later processing, as well as creating a subset of specialized schools, using the *specialized* flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Preparation and Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specDF = df[baseCols + specialCols]\n",
    "\n",
    "specDF['academicopportunities'] = specDF['academicopportunities1'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ',' + specDF['academicopportunities2'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['academicopportunities3'].replace(np.nan, '', regex=True).astype(str) \\\n",
    "+ ','+ specDF['academicopportunities4'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['academicopportunities5'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['academicopportunities6'].replace(np.nan, '', regex=True).astype(str)\n",
    "\n",
    "specDF['interests'] = specDF['interest1'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ',' + specDF['interest2'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['interest3'].replace(np.nan, '', regex=True).astype(str) \\\n",
    "+ ','+ specDF['interest4'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['interest5'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['interest6'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['interest7'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['interest8'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['interest9'].replace(np.nan, '', regex=True).astype(str)\\\n",
    "+ ','+ specDF['interest10'].replace(np.nan, '', regex=True).astype(str)\n",
    "\n",
    "specDF = specDF.drop(['academicopportunities1'\n",
    "                      ,'academicopportunities2'\n",
    "                      ,'academicopportunities3'\n",
    "                      ,'academicopportunities4'\n",
    "                      ,'academicopportunities5'\n",
    "                      ,'academicopportunities6'\n",
    "                     ,'interest1'\n",
    "                     ,'interest2'\n",
    "                     ,'interest3'\n",
    "                     ,'interest4'\n",
    "                     ,'interest5'\n",
    "                     ,'interest6'\n",
    "                     ,'interest7'\n",
    "                     ,'interest8'\n",
    "                     ,'interest9'\n",
    "                     ,'interest10']\n",
    "                     ,axis=1)\n",
    "\n",
    "specSchools = specDF[specDF['specialized'].notna() == True][['school_name'\n",
    "                                                             ,'overview_paragraph'\n",
    "                                                             ,'borough'\n",
    "                                                             ,'latitude'\n",
    "                                                             ,'longitude'\n",
    "                                                             ,'total_students'\n",
    "                                                            ,'neighborhood']]\n",
    "specSchools['total_students'] = pd.to_numeric(specSchools['total_students'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I am defining a few functions for data processing. The first function takes a field of comma-separated values and expands them into distinct records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/50731229/split-cell-into-multiple-rows-in-pandas-dataframe\n",
    "\n",
    "# return list from series of comma-separated strings\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "# calculate lengths of splits\n",
    "lens = specDF['interests'].str.split(',').map(len)\n",
    "\n",
    "# create new dataframe, repeating or chaining as appropriate\n",
    "df3 = pd.DataFrame({'school_name': np.repeat(specDF['school_name'], lens),\n",
    "                    'nta': np.repeat(specDF['nta'], lens),\n",
    "                    'interests': chainer(specDF['interests'])\n",
    "                   }\n",
    "                  )\n",
    "\n",
    "#df3.head(25)\n",
    "dfg3 = df3.groupby('interests').filter(lambda x: len(x) > 1)\n",
    "dfg3 = dfg3.groupby('interests').size()\\\n",
    "                             .reset_index(name='count') \\\n",
    "                             .sort_values(['count'], ascending=False)\n",
    "\n",
    "dfg3.replace('', np.nan, inplace=True)\n",
    "dfg3.dropna(subset=['interests'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to create a cartesian product between feeder schools and specialized schools for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/53699012/performant-cartesian-product-cross-join-with-pandas\n",
    "def cartesian_product_basic(left, right):\n",
    "    return (\n",
    "       left.assign(key=1).merge(right.assign(key=1), on='key').drop('key', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par1 = 'Specifically, we want to look at the distance between feeder schools and specialized schools, \\\n",
    "including getting data on the closest specialized school to a feeder school. Also doing some data manipulation \\\n",
    "to create numerical data. Offer count and tester count both had a bucket for 0-5. We want to be able to use them in \\\n",
    "visuals, and also to calculate an acceptance rate. Use a random integer between 0 and 5, then do some correcting to make \\\n",
    "sure that there are no records with offers > testers.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSHSAT = pd.read_csv('https://data.cityofnewyork.us/resource/uf53-ree9.csv')\n",
    "\n",
    "dfSHSAT=MSDirDF.set_index('schooldbn').join(dfSHSAT.set_index('feeder_school_dbn')).dropna()\n",
    "\n",
    "dfSHSAT.loc[dfSHSAT['number_of_offers'] == '0-5','number_of_offers'] = \\\n",
    "dfSHSAT['number_of_offers'].apply(lambda x: np.random.randint(0,5))\n",
    "\n",
    "dfSHSAT.loc[dfSHSAT['count_of_testers'] == '0-5','count_of_testers'] = \\\n",
    "dfSHSAT['count_of_testers'].apply(lambda x: np.random.randint(0,5))\n",
    "\n",
    "dfSHSAT['number_of_offers'] = dfSHSAT['number_of_offers'].astype('int32')\n",
    "dfSHSAT['count_of_testers'] = dfSHSAT['count_of_testers'].astype('int32')\n",
    "\n",
    "dfSHSAT[dfSHSAT['number_of_offers'] > dfSHSAT['count_of_testers']]['number_of_offers'] = \\\n",
    "dfSHSAT[dfSHSAT['number_of_offers'] > dfSHSAT['count_of_testers']]['count_of_testers']\n",
    "\n",
    "feederDF = cartesian_product_basic(dfSHSAT,specSchools[['school_name','latitude','longitude']])\n",
    "\n",
    "feederDF['distance'] = [\n",
    "    geopy.distance.distance((a, b), (c, d)).km\n",
    "    for a, b, c, d in feederDF[['latitude_x', 'longitude_x', 'latitude_y', 'longitude_y']].values\n",
    "]\n",
    "\n",
    "feederDF['acceptance_rate'] = feederDF['number_of_offers']/feederDF['count_of_testers']\n",
    "feederDF['acceptance_rate'] = feederDF['acceptance_rate'].replace(np.inf, 0).replace(np.NaN, 0)\n",
    "\n",
    "feed2 = feederDF.groupby(['feeder_school_name'\n",
    "                          , 'count_of_testers'\n",
    "                          , 'number_of_offers'\n",
    "                          , 'latitude_x'\n",
    "                          , 'longitude_x'\n",
    "                          , 'acceptance_rate'\n",
    "                         ], as_index=False)['distance'].min()\n",
    "\n",
    "#np.unique(feederDF['school_name'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MapBox (via Plotly plugin) for city-focused geo visuals. Default Plotly maps are only available at more macro levels (globe, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MBToken = 'pk.eyJ1Ijoic2NvaGVuZGUiLCJhIjoiY2szemMxczZoMXJhajNrcGRsM3cxdGdibiJ9.2oazpPgLvgJGF9EBOYa9Wg'\n",
    "px.set_mapbox_access_token(MBToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specText = 'Below is a map of all schools marked as \"Specialized\", broken up by borough (color). The size of the circle \\\n",
    "denotes enrollment size. The four largest circles are the oldest specialized schools: Stuyvesant, Bronx Science and Brooklyn Tech, \\\n",
    "which specialize in STEM; and Laguardia, which specializes in the arts). These are also the oldest specialized schools. The \\\n",
    "smaller circles are relative newcomers to the specialized admissions process, and show that an expansion of the system is \\\n",
    "already underway'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specFig = px.scatter_mapbox(specSchools.dropna()\n",
    "                        , lat=\"latitude\"\n",
    "                        , lon=\"longitude\"\n",
    "                        , color=\"borough\"\n",
    "                        , size=\"total_students\"\n",
    "                        , text=\"school_name\"\n",
    "                        , hover_name=\"school_name\"\n",
    "                        , hover_data=[\"neighborhood\"]\n",
    "                        , size_max=15\n",
    "                        , zoom=9\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intText = 'Taking a look at the breakdown in popular interests in non-specialized schools. Science/Tech takes up a lot of \\\n",
    "space, but there is a lot of interest in Humanities. As of now, there are no schools which specialize in social sciences.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intFig = go.Figure(data=[go.Pie(labels=dfg3['interests'], values=dfg3['count'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distText = 'Scatter showing min distance from any specialized school using color gradient, and number of specialized test \\\n",
    "takers as marker size. The large, dark circles indicate a school with a large number of students interested in attending \\\n",
    "one of the specialized schools, but that are situated inconveniently far away.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distFig = px.scatter_mapbox(feed2.dropna()\n",
    "                        , lat=\"latitude_x\"\n",
    "                        , lon=\"longitude_x\"\n",
    "                        , color=\"distance\"\n",
    "                        , size=\"count_of_testers\"\n",
    "                        , color_continuous_scale='Greens'#px.colors.cyclical.IceFire\n",
    "                        , size_max=15\n",
    "                        , zoom=10\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficText1 = 'Here we are using scattermapbox lines as a sort of traffic map, with line thickness determined by the number of test \\\n",
    "takers (which in theory indicates an interest in attending a specialized school). A large circle denotes a high acceptance rate. \\\n",
    "To reduce clutter, we are only looking at the 40 most remote schools.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig2 = go.Figure()\n",
    "\n",
    "stuyCoord = {'lon': feederDF[feederDF['school_name'] == 'Stuyvesant High School']['longitude_y'].iloc[1]\n",
    "            ,'lat': feederDF[feederDF['school_name'] == 'Stuyvesant High School']['latitude_y'].iloc[1]\n",
    "            }\n",
    "\n",
    "stuyDF = feederDF[feederDF['school_name'] == 'Stuyvesant High School'].sort_values('distance',ascending = False).head(40)\n",
    "stuyDF2 = feederDF[feederDF['school_name'] == 'Stuyvesant High School'].sort_values('distance',ascending = True).head(40)\n",
    "\n",
    "for i in range(len(stuyDF)):\n",
    "    fig2.add_trace(go.Scattermapbox(\n",
    "        mode = \"markers+lines\",\n",
    "        lon = [stuyDF.iloc[i]['longitude_x'],stuyDF.iloc[i]['longitude_y']],\n",
    "        lat = [stuyDF.iloc[i]['latitude_x'],stuyDF.iloc[i]['latitude_y']],\n",
    "        line = {'width': stuyDF.iloc[i]['count_of_testers']/20.0},\n",
    "        marker = {'size': stuyDF.iloc[i]['acceptance_rate']*30.0},\n",
    "        hovertext = stuyDF.iloc[i]['feeder_school_name'] + ' <-> ' + stuyDF.iloc[i]['school_name'],\n",
    "        #legendgroup = feederDF.iloc[i]['school_name']\n",
    "        showlegend = False\n",
    "    )\n",
    "                  )\n",
    "\n",
    "fig2.update_layout(\n",
    "    margin ={'l':0,'t':0,'b':0,'r':0},\n",
    "    mapbox = {\n",
    "        'center': stuyCoord,\n",
    "        'style': \"stamen-terrain\",\n",
    "        #'center': {'lon': stuyDF['longitude_x'].mean(), 'lat': stuyDF['latitude_x'].mean()},\n",
    "        'zoom': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficText2 = 'Doing the same for Laguardia High School for the arts, although it is unclear from this data whether \\\n",
    "\"test takers\" includes auditioners.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = go.Figure()\n",
    "\n",
    "lagCoord = {'lon': feederDF[feederDF['school_name'] == 'Fiorello H. LaGuardia High School of Music & Art and Performing Arts']['longitude_y'].iloc[1]\n",
    "            ,'lat': feederDF[feederDF['school_name'] == 'Fiorello H. LaGuardia High School of Music & Art and Performing Arts']['latitude_y'].iloc[1]\n",
    "            }\n",
    "\n",
    "lagDF = feederDF[feederDF['school_name'] == 'Fiorello H. LaGuardia High School of Music & Art and Performing Arts'].sort_values('distance',ascending = False).head(40)\n",
    "lagDF2 = feederDF[feederDF['school_name'] == 'Fiorello H. LaGuardia High School of Music & Art and Performing Arts'].sort_values('distance',ascending = True).head(40)\n",
    "\n",
    "for i in range(len(lagDF)):\n",
    "    fig3.add_trace(go.Scattermapbox(\n",
    "        mode = \"markers+lines\",\n",
    "        lon = [lagDF.iloc[i]['longitude_x'],lagDF.iloc[i]['longitude_y']],\n",
    "        lat = [lagDF.iloc[i]['latitude_x'],lagDF.iloc[i]['latitude_y']],\n",
    "        line = {'width': lagDF.iloc[i]['count_of_testers']/20.0},\n",
    "        marker = {'size': lagDF.iloc[i]['acceptance_rate']*30.0},\n",
    "        hovertext = lagDF.iloc[i]['feeder_school_name'] + ' <-> ' + lagDF.iloc[i]['school_name'],\n",
    "        #legendgroup = feederDF.iloc[i]['school_name']\n",
    "        showlegend = False\n",
    "    )\n",
    "                  )\n",
    "\n",
    "fig3.update_layout(\n",
    "    margin ={'l':0,'t':0,'b':0,'r':0},\n",
    "    mapbox = {\n",
    "        'center': lagCoord,\n",
    "        'style': \"stamen-terrain\",\n",
    "        #'center': {'lon': stuyDF['longitude_x'].mean(), 'lat': stuyDF['latitude_x'].mean()},\n",
    "        'zoom': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash()\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([html.H1('NYC Specialized Schools')], style={'textAlign': 'center'}),\n",
    "    html.Div([html.H2('Sam Cohen-Devries, CUNY SPS DATA608, Fall 2019')], style={'textAlign': 'left'}),\n",
    "    html.Div(children=intro),\n",
    "    html.Div(children=specText),\n",
    "    dcc.Graph(children=specFig),\n",
    "    html.Div(children=intText),\n",
    "    dcc.Graph(figure=intFig),\n",
    "    html.Div(children=distText),\n",
    "    dcc.Graph(figure=distFig),\n",
    "    html.Div(children=trafficText1),\n",
    "    dcc.Graph(figure=fig2),\n",
    "    html.Div(children=trafficText2),\n",
    "    dcc.Graph(figure=fig3),\n",
    "])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
